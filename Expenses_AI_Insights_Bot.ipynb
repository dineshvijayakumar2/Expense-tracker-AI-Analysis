{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55413edf-3f7e-4167-9cd4-a6659ebf2da3",
   "metadata": {},
   "source": [
    "# Intelligent Bot to get Financial Data Insights on Personal Expenses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8b5d32-10e4-4e8b-adde-e2a482dd67c1",
   "metadata": {},
   "source": [
    "### Loading Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6138ba-23ed-4ba3-be3d-9d855f608271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4b74374-cec0-47a8-aa2b-d606ce5756f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import PIL.Image\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "import vertexai.preview.generative_models as generative_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1858b82b-5239-42f3-a043-7ec680283d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyDffeaiwB02FFBn2BAkmtEilLAANQP72M8\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv('GOOGLE_GEMINI_API_KEY')\n",
    "print(api_key)\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eded83-666b-4666-b6bb-6d2a7220a979",
   "metadata": {},
   "source": [
    "### Exporting data from Quickbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c37d136-dcf1-4adf-857c-ad05e505b8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = \"builderprogram-dvijayakumar.quickbase.com\"\n",
    "usertoken = os.getenv(\"QB_USERTOKEN\")\n",
    "tableid = \"btnwn8n6q\"\n",
    "reportid = \"27\"\n",
    "headers = {'QB-Realm-Hostname': domain, 'User-Agent': 'PythonUtility', 'Authorization': 'QB-USER-TOKEN ' + usertoken}\n",
    "perBatchRecordsCount = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf0d6415-89dd-4a27-8dbf-08a92e7ecce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQBBatchDF(batchRecordCount, skipStart, firstIter):\n",
    "    print(\"Generating the records from \" + str(int(skipStart) + 1) + \"...\")\n",
    "    url = 'https://api.quickbase.com/v1/reports/' + reportid + '/run?tableId=' + tableid + '&skip=' + str(\n",
    "        skipStart) + '&top=' + str(batchRecordCount)\n",
    "    queryBody = {\n",
    "    }\n",
    "\n",
    "    retryCount = 0\n",
    "    qbdataDF = pd.DataFrame()\n",
    "    qbrecordsDict = dict()\n",
    "    qbfieldsDict = []\n",
    "\n",
    "    try:\n",
    "        print(url)\n",
    "        rQuery = requests.post(url,\n",
    "                               headers=headers,\n",
    "                               json=queryBody,\n",
    "                               verify=False\n",
    "                               )\n",
    "\n",
    "        if rQuery.status_code == 200:\n",
    "            responseQuery = json.loads(json.dumps(rQuery.json(), indent=4))\n",
    "            qbfieldsDict = list(responseQuery[\"fields\"])\n",
    "            qbrecordsDict = (responseQuery[\"data\"])\n",
    "            qbdataDF = pd.DataFrame.from_dict(qbrecordsDict, orient=\"columns\")\n",
    "            for col in qbdataDF.columns:\n",
    "                qbdataDF[col] = pd.json_normalize(qbdataDF[col], max_level=0)\n",
    "        else:\n",
    "            print(\"Skipped the records from \" + str(int(skipStart) + 1) + \" to \" + str(\n",
    "                int(skipStart) + perBatchRecordsCount) + \"...\")\n",
    "\n",
    "        return qbdataDF, qbfieldsDict, rQuery.status_code\n",
    "    except IndexError as e:\n",
    "        print(e)\n",
    "        while retryCount < 3:\n",
    "            retryCount += 1\n",
    "            print(\"Retry \"+str(retryCount))\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "def exportqbdata(batchRecordCount, skipStart):\n",
    "    if len(str(batchRecordCount)) == 0:\n",
    "        batchRecordCount = perBatchRecordsCount\n",
    "    if (int(batchRecordCount) <= perBatchRecordsCount):\n",
    "        outputdf, qbfieldsDict, statusCode = getQBBatchDF(batchRecordCount, skipStart, firstIter=True)\n",
    "        outputdf.to_csv(\"qbdata.csv\", encoding=\"utf-8-sig\")\n",
    "    else:\n",
    "        outputdf = pd.DataFrame()\n",
    "        lastbatch = False\n",
    "        skipStartIter = int(skipStart)\n",
    "        firstIter = True\n",
    "        print(batchRecordCount, skipStart)\n",
    "        while lastbatch == False:\n",
    "            qbbatchdf, qbfieldsDict, statusCode = getQBBatchDF(perBatchRecordsCount, skipStartIter, firstIter)\n",
    "            print(statusCode)\n",
    "            if statusCode == 200:\n",
    "                firstIter = False\n",
    "                outputdf = outputdf.append(qbbatchdf)\n",
    "                outputdf.to_csv(\"qbdata.csv\", encoding=\"utf-8-sig\")\n",
    "                skipStartIter += perBatchRecordsCount\n",
    "                if skipStartIter > (int(batchRecordCount)+int(skipStart)):\n",
    "                    lastbatch = True\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    qbfieldsDF = pd.DataFrame.from_dict(qbfieldsDict)\n",
    "    qbfieldsDF.set_index(\"id\", inplace=True)\n",
    "    qbcols = outputdf.columns\n",
    "    qbcolnames = []\n",
    "    for col in qbcols:\n",
    "        qbcolnames.append(qbfieldsDF[\"label\"][int(col)])\n",
    "    outputdf.columns = qbcolnames\n",
    "    outputdf.reset_index(drop=True, inplace=True)\n",
    "    outputdf.to_csv(\"qbdata.csv\", encoding=\"utf-8-sig\")\n",
    "    print(f\"Number of record Queried from Quickbase: {outputdf.shape[0]}\")\n",
    "    return outputdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "adcfb6ea-6795-4fa2-926e-573a4d906924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expenses_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b144dcb6-e85c-40b8-9ee0-b45ba1e0b6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of records to be queried in the batch. If left blank, 1000 will be considered... 1000\n",
      "Enter the skip value... 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the records from 1...\n",
      "https://api.quickbase.com/v1/reports/27/run?tableId=btnwn8n6q&skip=0&top=1000\n",
      "(802, 5)\n",
      "Number of record Queried from Quickbase 802\n"
     ]
    }
   ],
   "source": [
    "batchRecordCount = input(\"Enter the number of records to be queried in the batch. If left blank, \" + str(perBatchRecordsCount) + \" will be considered...\")\n",
    "skipStart = input(\"Enter the skip value...\")\n",
    "expenses_data_df = exportqbdata(batchRecordCount, skipStart)\n",
    "\n",
    "# Convert DataFrame to string with pipe separator for columns and newline for rows\n",
    "formatted_data = expenses_data_df.to_csv(sep='|', index=False, line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756799f6-01bb-4d1b-ade5-38be60d8c95c",
   "metadata": {},
   "source": [
    "### Chat Conversation with Gemini Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d031586f-835d-43af-8446-63e93ead71b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "import vertexai.preview.generative_models as generative_models\n",
    "\n",
    "def multiturn_generate_content():\n",
    "    # Initialize the Vertex AI and model configuration\n",
    "    vertexai.init(project=\"vegan-website-421304\", location=\"us-central1\")\n",
    "    model = GenerativeModel(\n",
    "        \"gemini-1.0-pro\",\n",
    "        system_instruction=[textsi_1]\n",
    "    )\n",
    "\n",
    "    # Start a chat session with the model\n",
    "    chat = model.start_chat()\n",
    "\n",
    "    # Configuration for the generation process\n",
    "    generation_config = {\n",
    "        \"max_output_tokens\": 8192,\n",
    "        \"temperature\": 1,\n",
    "        \"top_p\": 0.95,\n",
    "    }\n",
    "\n",
    "    # Safety settings to control content generation\n",
    "    safety_settings = {\n",
    "        generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "        generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "        generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "        generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    }\n",
    "\n",
    "    print(\"Chat session started. Type 'chat done' to end the conversation.\")\n",
    "\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_message = input(\"You: \")\n",
    "\n",
    "        # Check if the user wants to end the chat\n",
    "        if user_message.lower() == \"chat done\":\n",
    "            print(\"Ending chat session. Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Send the user message to the chat and get the response\n",
    "        response = chat.send_message(\n",
    "            [user_message],\n",
    "            generation_config=generation_config,\n",
    "            safety_settings=safety_settings\n",
    "        )\n",
    "\n",
    "        # Print the model's response\n",
    "        print(\"AI:\", response.candidates[0].content.parts[0].text)\n",
    "\n",
    "# System instruction text for financial analyst context\n",
    "textsi_1 = \"You are a financial analyst, you need to answer questions based on the below data\\n\" + formatted_data\n",
    "\n",
    "# Start the interactive chat function\n",
    "multiturn_generate_content()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7299c4e-cd85-4837-af7c-545c9625717b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:  Hello again! ðŸ‘‹ Is there anything specific I can help you with right now? ðŸ˜Š\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  can you give me summary of March 2024 data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI:  ## March 2024 Summary: Custom Insights\n",
      "\n",
      "Here's a tailored summary of your March spending, incorporating custom insights based on your preferences:\n",
      "\n",
      "**Category Focus:**\n",
      "\n",
      "* Groceries: Focusing on cost-saving strategies and breakdowns per subcategory\n",
      "* Travel: Identifying areas for optimization and cost reduction\n",
      "* Investments: Ensuring alignment with goals and diversification\n",
      "* Learning/Digital: Reviewing subscriptions and exploring cost-effective alternatives\n",
      "* Health: Tracking expenditure against budget and considering preventative measures\n",
      "\n",
      "**Insights:**\n",
      "\n",
      "* **Groceries:**\n",
      "    * Monthly grocery expense is â‚¹31,812, forming 27% of your total spending.\n",
      "    * Subcategories like milk, vegetables, fruits constitute significant portions of the grocery budget.\n",
      "    * Explore cost-saving strategies like meal planning, buying in bulk, exploring seasonal produce, seeking substitutes for expensive items.\n",
      "    * Consider analyzing data from previous months to identify trends and potential optimization areas.\n",
      "\n",
      "* **Travel:**\n",
      "    * Travel expenditure is â‚¹28,726, forming 24.4% of your total spending.\n",
      "    * Significant expenses include petrol, flights, car service.\n",
      "    * Explore alternatives like public transportation, carpooling, budget-friendly accommodation options.\n",
      "    * Analyze your travel frequency and duration to identify areas for optimization.\n",
      "\n",
      "* **Investments:**\n",
      "    * Investment amount is â‚¹4676, constituting 4.0% of your total spending.\n",
      "    * Evaluate your investment strategy for alignment with your financial goals.\n",
      "    * Consider diversification to mitigate risks and spread investments across various asset classes.\n",
      "\n",
      "* **Learning/Digital:**\n",
      "    * Learning/Digital expenses are â‚¹3,972, forming 3.4% of your total spending.\n",
      "    * Expenses include subscriptions, online courses, software.\n",
      "    * Review your subscriptions and courses to identify redundancies or areas where cost-effective alternatives exist.\n",
      "\n",
      "* **Health:**\n",
      "    * Health expenditure is â‚¹16,727, forming 14.2% of your total spending.\n",
      "    * Expenses include medicines, doctor consultations, health checkups.\n",
      "    * Track your health expenditure against your budget to ensure you're staying within limits.\n",
      "    * Explore preventative measures and healthy habits to potentially reduce expenses in the long run.\n",
      "\n",
      "**Next Steps:**\n",
      "\n",
      "* Based on the insights, consider implementing specific actions for each category.\n",
      "* Monitor your spending over time to track progress and identify further optimization opportunities.\n",
      "* Consider using budgeting tools to effectively manage your finances.\n",
      "\n",
      "**Additional Information:**\n",
      "\n",
      "* You also made frequent use of UPI payments, which accounted for â‚¹14,500 of your total spending.\n",
      "* Your primary credit cards were HDFC Credit and Kotak Credit.\n",
      "* Notable purchases included groceries from Bigbasket and Kaleesuwari Groceries, petrol, and flights.\n",
      "\n",
      "**This summary is customized to your preferences and tailored to provide comprehensive insights into your March spending. \n",
      "\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "url = 'https://us-central1-vegan-website-421304.cloudfunctions.net/expense_analysis_gemini'\n",
    "\n",
    "headers = {}\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Get user input\n",
    "        user_message = input(\"You: \")\n",
    "        \n",
    "        # Check if the user wants to end the chat\n",
    "        if user_message.lower() == \"chat done\":\n",
    "            print(\"Ending chat session. Goodbye!\")\n",
    "            break\n",
    "        queryBody = {\n",
    "            \"user_input\": user_message\n",
    "        }\n",
    "        # Send the user message to the chat and get the response\n",
    "        rQuery = requests.post(url,\n",
    "                           headers=headers,\n",
    "                           json=queryBody,\n",
    "                           verify=False)\n",
    "        print(\"AI: \", json.loads(rQuery.text)['message'])\n",
    "except:\n",
    "    print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9f6d6a-6607-4d9a-bf18-d29313b3f412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
